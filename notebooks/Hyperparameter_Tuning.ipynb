{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier()\n",
    "}\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grid = {\n",
    "    \"Decision Tree Classifier\": {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [None, 10, 15, 23, 35, 50],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\", None]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [int(x) for x in np.linspace(start=100, stop=2000, num=10)],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "        \"max_depth\": [int(x) for x in np.linspace(10, 1000, num=10)],\n",
    "        \"min_samples_split\": [2, 5, 10, 14],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 6, 8],\n",
    "        \"bootstrap\": [True, False]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2, 0.3],\n",
    "        \"n_estimators\": [int(x) for x in np.linspace(start=50, stop=1000, num=10)],\n",
    "        \"max_depth\": [3, 4, 5, 6, 8, 10],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "        \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "        \"reg_alpha\": [0, 0.001, 0.005, 0.01, 0.05]\n",
    "    }\n",
    "}\n",
    "\n",
    "def train_algorithms(models, X_train, y_train, X_test, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        # Hyperparameter tuning using Randomized Search\n",
    "        if model_name in param_grid:\n",
    "            random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid[model_name],\n",
    "                                               n_iter=10, scoring='accuracy', n_jobs=-1, cv=5, verbose=2)\n",
    "            random_search.fit(X_train, y_train)\n",
    "            best_model = random_search.best_estimator_\n",
    "        else:\n",
    "            best_model = model\n",
    "        \n",
    "        # Cross-validation\n",
    "        cross_val_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        \n",
    "        # Training set performance\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        \n",
    "        # Test set performance\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Save best model\n",
    "        joblib.dump(best_model, f\"../models/{model_name}_best_joblib\")\n",
    "        \n",
    "        # Print results\n",
    "        print(model_name)\n",
    "        print(\"Best Model:\")\n",
    "        print(best_model)\n",
    "        \n",
    "        print(\"Cross-Validation Mean Accuracy: {:.4f}\".format(np.mean(cross_val_scores)))\n",
    "        \n",
    "        print(\"Model performance for Training set\")\n",
    "        print(\"- Accuracy Score: {:.4f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "        # Include other performance metrics here\n",
    "        \n",
    "        print(\"Model performance for Test set\")\n",
    "        print(\"- Accuracy Score: {:.4f}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "        # Include other performance metrics here\n",
    "\n",
    "        print(\"=\" * 35)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
